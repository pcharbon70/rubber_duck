# Feature: Provider-Specific LLM Agents (15.4.2)

## Overview

Create provider-specific autonomous agents that wrap individual LLM providers (OpenAI, Anthropic, Local) as independent agents. These agents handle provider-specific concerns while communicating through signals with the LLM Router Agent.

## Analysis of Existing Code

### Current Implementation
1. **Provider Behavior**: `RubberDuck.LLM.Provider`
   - Defines common interface for all providers
   - Supports feature detection
   - Token estimation capabilities

2. **Existing Providers**:
   - `RubberDuck.LLM.Providers.OpenAI`: GPT models integration
   - `RubberDuck.LLM.Providers.Anthropic`: Claude models integration
   - `RubberDuck.LLM.Providers.Ollama`: Local models via Ollama
   - `RubberDuck.LLM.Providers.TGI`: Text Generation Interface
   - `RubberDuck.LLM.Providers.Mock`: Testing provider

3. **Key Provider Responsibilities**:
   - Request formatting for specific APIs
   - HTTP communication
   - Response parsing
   - Error handling
   - Feature support detection

## Design Decisions

### 1. Agent Architecture
- Create a base ProviderAgent module for common functionality
- Each provider gets its own agent module extending the base
- Agents wrap existing provider modules, not replace them
- Signal-based communication with LLM Router Agent

### 2. Signal Types
- `provider_request`: Execute LLM request through provider
- `provider_response`: Return completion response
- `provider_status`: Report health and metrics
- `provider_error`: Report execution errors
- `feature_check`: Check feature support
- `token_estimate`: Estimate token usage

### 3. State Management
```elixir
schema: [
  provider_module: [type: :atom, required: true],
  provider_config: [type: :map, required: true],
  active_requests: [type: :map, default: %{}],
  metrics: [type: :map, default: %{
    total_requests: 0,
    successful_requests: 0,
    failed_requests: 0,
    total_tokens: 0,
    avg_latency: 0
  }],
  rate_limiter: [type: :map, default: %{
    limit: nil,
    window: nil,
    current_count: 0,
    window_start: nil
  }],
  circuit_breaker: [type: :map, default: %{
    state: :closed,  # :closed, :open, :half_open
    failure_count: 0,
    last_failure: nil,
    threshold: 5,
    timeout: 60_000  # 1 minute
  }]
]
```

### 4. Provider Agent Features
- **Request Execution**: Handle provider-specific API calls
- **Rate Limiting**: Enforce provider-specific limits
- **Circuit Breaking**: Prevent cascading failures
- **Metrics Collection**: Track performance and usage
- **Feature Reporting**: Advertise provider capabilities
- **Error Enrichment**: Add provider context to errors

### 5. Integration Points
- Uses existing provider modules for actual API calls
- Receives requests from LLM Router Agent
- Reports health to monitoring systems
- Integrates with telemetry for observability

## Implementation Plan

### Phase 1: Base Provider Agent
1. Create ProviderAgent base module
2. Implement common signal handlers
3. Add rate limiting logic
4. Build circuit breaker
5. Create metrics tracking

### Phase 2: OpenAI Provider Agent
1. Create OpenAIProviderAgent
2. Configure for OpenAI-specific limits
3. Add GPT-4 specific handling
4. Implement streaming support
5. Add function calling support

### Phase 3: Anthropic Provider Agent
1. Create AnthropicProviderAgent
2. Configure for Claude models
3. Add context window handling
4. Implement safety features
5. Add vision support

### Phase 4: Local Provider Agent
1. Create LocalProviderAgent base
2. Add Ollama integration
3. Implement resource monitoring
4. Add model loading/unloading
5. Create performance optimization

### Phase 5: Testing & Documentation
1. Create comprehensive test suite
2. Add integration tests with router
3. Document signal flows
4. Create usage examples

## Signal Flow Examples

### Request Execution Flow
```
1. Receive provider_request from LLM Router
   - request_id, messages, options, model
2. Check rate limits
3. Check circuit breaker state
4. Execute through provider module
5. Update metrics
6. Emit provider_response or provider_error
```

### Health Monitoring Flow
```
1. Periodic health check timer
2. Test provider connectivity
3. Check resource availability
4. Calculate health score
5. Emit provider_status signal
```

### Circuit Breaker Flow
```
1. Track consecutive failures
2. Open circuit after threshold
3. Reject requests when open
4. Allow test request after timeout
5. Close circuit on success
```

## Success Criteria
- Provider agents handle all provider-specific concerns
- Clean signal-based interface with router
- Robust error handling and recovery
- Comprehensive metrics and monitoring
- Maintains compatibility with existing providers